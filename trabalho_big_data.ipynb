{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wpdias1/AED/blob/main/trabalho_big_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TazvTwqp89Au"
      },
      "source": [
        "# Comandos para realização do trabalho da matéria de Big Data com uso da biblioteca PySpark.\n",
        "\n",
        "Este notebook foi projetado para guiar os alunos na realização das práticas de Big Data utilizando PySpark. Certifique-se de seguir cada etapa cuidadosamente para garantir a correta execução das atividades.\n",
        "\n",
        "Seu trabalho começará na célula 5. Execute as 4 primeiras células para iniciar a atividade.\n",
        "\n",
        "## <font color=red>Observação importante:</font>\n",
        "\n",
        "<font color=yellow>Trabalho realizado com uso da biblioteca pandas não será aceito!</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoAC_Re589Aw"
      },
      "source": [
        "## Upload do arquivo `imdb-reviews-pt-br.csv` para dentro do Google Colab\n",
        "\n",
        "Aqui, você fará o download do dataset necessário para as atividades. Certifique-se de que o arquivo foi descompactado corretamente antes de prosseguir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "rvq7ROBk89Ax",
        "outputId": "56b274fc-125c-4cbf-fb7f-276973c67fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-08 23:38:55--  https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49549692 (47M) [application/zip]\n",
            "Saving to: ‘imdb-reviews-pt-br.zip’\n",
            "\n",
            "\rimdb-reviews-pt-br.   0%[                    ]       0  --.-KB/s               \rimdb-reviews-pt-br. 100%[===================>]  47.25M   252MB/s    in 0.2s    \n",
            "\n",
            "2024-12-08 23:38:55 (252 MB/s) - ‘imdb-reviews-pt-br.zip’ saved [49549692/49549692]\n",
            "\n",
            "Archive:  imdb-reviews-pt-br.zip\n",
            "replace imdb-reviews-pt-br.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: imdb-reviews-pt-br.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip -O imdb-reviews-pt-br.zip\n",
        "!unzip imdb-reviews-pt-br.zip\n",
        "!rm imdb-reviews-pt-br.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEQRRNrK89Ax"
      },
      "source": [
        "## Instalação manual das dependências para uso do pyspark no Google Colab\n",
        "\n",
        "Esta etapa garante que todas as bibliotecas necessárias para o PySpark sejam instaladas no Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "31iRcvpx89Ax",
        "outputId": "2c1fdf59-67a0-40c6-b962-d99784124f71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG-SD7sn89Ay"
      },
      "source": [
        "## Importar, instanciar e criar a SparkSession\n",
        "\n",
        "A SparkSession é o ponto de entrada para usar o PySpark. Certifique-se de configurar corretamente o nome do aplicativo e o master."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "oEVrUHW689Ay"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "appName = \"PySpark Trabalho de Big Data\"\n",
        "master = \"local\"\n",
        "\n",
        "spark = SparkSession.builder.appName(appName).master(master).getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85_D5F8889Ay"
      },
      "source": [
        "## Criar spark dataframe do CSV utilizando o método read.csv do spark\n",
        "\n",
        "Não altere este código e use o dataframe imdb_df criado aqui em todo o seu trabalho. A criação de um dataframe diferente deste poderá causar erros na coluna sentiment e isso refletirá em erros de resposta das questões."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "zdDH17Zd89Ay"
      },
      "outputs": [],
      "source": [
        "imdb_df = spark.read.csv('imdb-reviews-pt-br.csv',\n",
        "                         header=True,\n",
        "                         quote=\"\\\"\",\n",
        "                         escape=\"\\\"\",\n",
        "                         encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA7h_iE489Ay"
      },
      "source": [
        "# Questão 1\n",
        "\n",
        "Nesta questão, você irá calcular a soma dos IDs para entradas onde o sentimento ('sentiment') é 'neg'.\n",
        "\n",
        "### Objetivo:\n",
        "- Usar a coluna 'sentiment' como chave e somar os valores da coluna 'id'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "-VXpCCW089Az",
        "outputId": "e1beb0f7-f0fb-4fcc-8adc-6c8bb1e2b62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------------------+---------+\n",
            "| id|             text_en|             text_pt|sentiment|\n",
            "+---+--------------------+--------------------+---------+\n",
            "|  1|Once again Mr. Co...|Mais uma vez, o S...|      neg|\n",
            "|  2|This is an exampl...|Este é um exemplo...|      neg|\n",
            "|  3|First of all I ha...|Primeiro de tudo ...|      neg|\n",
            "|  4|Not even the Beat...|Nem mesmo os Beat...|      neg|\n",
            "|  5|Brass pictures mo...|Filmes de fotos d...|      neg|\n",
            "+---+--------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text_en: string (nullable = true)\n",
            " |-- text_pt: string (nullable = true)\n",
            " |-- sentiment: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Função MAP Transformar cada linha em tupla (chave, valor)\n",
        "def map1(row):\n",
        "    try:\n",
        "        return (row['sentiment'], int(row['id']))\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar linha: {row} -> {e}\")\n",
        "        return None\n",
        "\n",
        "# Aplica a função MAP e filtra entradas válidas\n",
        "mapped_rdd = imdb_df.rdd.map(map1).filter(lambda x: x is not None)\n",
        "\n",
        "# Filtra apenas os casos onde 'sentiment' é igual a 'neg'\n",
        "filtered_rdd = mapped_rdd.filter(lambda x: x[0] == 'neg')\n",
        "\n",
        "# Visão inicial dos dados\n",
        "imdb_df.show(5)\n",
        "\n",
        "# Verificar dataFrame para confirmar as colunas\n",
        "imdb_df.printSchema()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "n_FZFNmd89Az"
      },
      "outputs": [],
      "source": [
        "def reduceByKey(x,y):\n",
        "    # x e y são os valores (IDs) associados à mesma chave (sentiment)\n",
        "    # A função simplesmente soma x e y\n",
        "    return x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Bv4648tV89Az",
        "outputId": "71743b25-151d-44d7-cf92-f212c4b35ecb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado da soma de IDs para 'neg': [('neg', 459568555)]\n",
            "Minha RU: 4370725\n"
          ]
        }
      ],
      "source": [
        "# Linha de código para aplicar o map/reduce no seu dataframe spark\n",
        "result = filtered_rdd.reduceByKey(reduceByKey).collect()\n",
        "# Coloque aqui o código para imprimir o resultado. Não esqueça seu RU:\n",
        "print(\"Resultado da soma de IDs para 'neg':\", result)\n",
        "print(\"Minha RU: 4370725\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP8Wsxm689Az"
      },
      "source": [
        "# Questão 2:\n",
        "\n",
        "Nesta questão, você irá calcular a diferença no número total de palavras entre textos negativos em português e inglês.\n",
        "\n",
        "### Objetivo:\n",
        "- Contar as palavras em cada idioma (colunas 'text_pt' e 'text_en') para entradas onde o sentimento ('sentiment') é 'neg'.\n",
        "- Subtrair o total de palavras em inglês do total em português."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUMYeFnu89Az"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave de uma tupla principal e como valor uma outra tupla com a soma das palavras de cada idioma como valor.\n",
        "\n",
        "A função map irá transformar cada linha do dataframe em uma tupla (chave-valor), onde:\n",
        "- Chave: coluna 'sentiment'\n",
        "- Valor: Nova tupla com:\n",
        "  - Elemento 0: soma das palavras da coluna 'text_en'\n",
        "  - Elemento 1: soma das palavras da coluna 'text_pt'\n",
        "\n",
        "OU\n",
        "- Chave: coluna 'sentiment'\n",
        "- Valor: (soma das palavras da coluna 'text_pt') - (soma das palavras da coluna 'text_en')\n",
        "  \n",
        "\n",
        "Para contar as palavras deve-se primeiro separar os textos em uma lista de palavras para então descobrir o tamanho desta lista.\n",
        "Dicas:\n",
        "\n",
        "1. Use o método .split() e não .split(\" \") de string para separar as palavras em uma lista ou use a função split(coluna de texto, regex) do pyspark com o regex igual à \"[ ]+\" ou \"\\s+\"\n",
        "2. Use len() para descobrir o tamanho da lista de palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "KnSGlUkf89Az",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a770e63c-a006-4619-fb5d-6eb5815a1d3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------------------+--------------------+---------+\n",
            "| id|             text_en|             text_pt|sentiment|\n",
            "+---+--------------------+--------------------+---------+\n",
            "|  1|Once again Mr. Co...|Mais uma vez, o S...|      neg|\n",
            "|  2|This is an exampl...|Este é um exemplo...|      neg|\n",
            "|  3|First of all I ha...|Primeiro de tudo ...|      neg|\n",
            "|  4|Not even the Beat...|Nem mesmo os Beat...|      neg|\n",
            "|  5|Brass pictures mo...|Filmes de fotos d...|      neg|\n",
            "+---+--------------------+--------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- text_en: string (nullable = true)\n",
            " |-- text_pt: string (nullable = true)\n",
            " |-- sentiment: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Função MAP transforma cada linha em uma tupla com contagem de palavras\n",
        "def map2(row):\n",
        "    try:\n",
        "        sentiment = row['sentiment']\n",
        "        if sentiment != 'neg':\n",
        "            return None\n",
        "\n",
        "        # Separa as palavras e calcula o total de cada idioma\n",
        "        words_en = len(row['text_en'].split()) if row['text_en'] else 0\n",
        "        words_pt = len(row['text_pt'].split()) if row['text_pt'] else 0\n",
        "\n",
        "        # Retorna chave-valor para o RDD\n",
        "        return (sentiment, (words_en, words_pt))\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar linha: {row} -> {e}\")\n",
        "        return None\n",
        "\n",
        "# Aplica função MAP e filtra entradas válidas\n",
        "mapped_rdd = imdb_df.rdd.map(map2).filter(lambda x: x is not None)\n",
        "\n",
        "# Visão inicial dos dados\n",
        "imdb_df.show(5)\n",
        "\n",
        "# Verifica esquema do DataFrame para confirmar as colunas\n",
        "imdb_df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "CBzhF_bo89Az"
      },
      "outputs": [],
      "source": [
        "# Função REDUCE (renomeada para reduceByKey2): Somar palavras por idioma\n",
        "reduced_rdd = mapped_rdd.reduceByKey(\n",
        "    lambda x, y: (x[0] + y[0], x[1] + y[1])  # x[0] e y[0] para inglês, x[1] e y[1] para português\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "gSIzhGiv89Az",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60244564-7f21-4fa8-d328-2ba9017c3f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de palavras em inglês: 5400324\n",
            "Total de palavras em português: 5455273\n",
            "Diferença (português - inglês): 54949\n",
            "Minha RU: 4370725\n"
          ]
        }
      ],
      "source": [
        "# Coleta os resultados\n",
        "result = reduced_rdd.collect()\n",
        "\n",
        "# Calcula a diferença entre total de palavras em português e inglês\n",
        "if result:\n",
        "    total_en = result[0][1][0]  # Soma total de palavras em 'text_en'\n",
        "    total_pt = result[0][1][1]  # Soma total de palavras em 'text_pt'\n",
        "    difference = total_pt - total_en\n",
        "# Exibindo em tela\n",
        "    print(f\"Total de palavras em inglês: {total_en}\")\n",
        "    print(f\"Total de palavras em português: {total_pt}\")\n",
        "    print(f\"Diferença (português - inglês): {difference}\")\n",
        "    print(\"Minha RU: 4370725\")\n",
        "else:\n",
        "    print(\"Nenhum dado encontrado para 'sentiment' = 'neg'.\")\n",
        "\n",
        "# Finalizar a SparkSession\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1txOIWrrij-X"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}